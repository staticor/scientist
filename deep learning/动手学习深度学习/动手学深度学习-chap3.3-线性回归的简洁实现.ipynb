{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd, nd\n",
    "\n",
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "true_w, true_b = [2,-3.4], 4.2\n",
    "\n",
    "features = nd.random.normal(scale=1, shape=(num_examples, num_inputs))\n",
    "\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "\n",
    "labels += nd.random.normal(scale=0.01, shape=labels.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "\n",
    "from mxnet.gluon import data as gdata\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# 将训练数据的特征和标签组合\n",
    "\n",
    "dataset = gdata.ArrayDataset(features, labels)\n",
    "\n",
    "# 随机读取小批量\n",
    "data_iter = gdata.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[-0.37107468 -1.4219483 ]\n",
      " [ 0.26872492  1.0765359 ]\n",
      " [-1.3588097   1.1656759 ]\n",
      " [-1.8885834   0.6752996 ]\n",
      " [ 0.40762237 -0.8409864 ]\n",
      " [ 0.53874415  0.08753639]\n",
      " [-0.9203057  -0.2579334 ]\n",
      " [ 0.68650365  2.0535662 ]\n",
      " [ 0.07440522  0.21652144]\n",
      " [ 0.9143916   1.3179713 ]]\n",
      "<NDArray 10x2 @cpu(0)> \n",
      "[ 8.29892    1.0669702 -2.4718847 -1.8700022  7.871389   4.9876847\n",
      "  3.2231455 -1.4055421  3.6307526  1.5454857]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "\n",
    "net.add(nn.Dense(1))\n",
    "\n",
    "# 初始化模型参数\n",
    "\n",
    "from mxnet import init\n",
    "\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "\n",
    "from mxnet.gluon import loss as gloss\n",
    "\n",
    "# 平方损失 又称 L2范数损失\n",
    "\n",
    "loss = gloss.L2Loss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "# 定义优化算法\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.035202\n",
      "epoch 2, loss: 0.000128\n",
      "epoch 3, loss: 0.000048\n",
      "epoch 4, loss: 0.000048\n",
      "epoch 5, loss: 0.000048\n",
      "epoch 6, loss: 0.000048\n",
      "epoch 7, loss: 0.000048\n",
      "epoch 8, loss: 0.000048\n",
      "epoch 9, loss: 0.000048\n",
      "epoch 10, loss: 0.000048\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 训练模型\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        with autograd.record():\n",
    "            l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "    l = loss(net(features), labels)\n",
    "    print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, -3.4], \n",
       " [[ 1.9993746 -3.4000773]]\n",
       " <NDArray 1x2 @cpu(0)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = net[0]\n",
    "\n",
    "true_w, dense.weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.2, \n",
       " [4.2002907]\n",
       " <NDArray 1 @cpu(0)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_b, dense.bias.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结\n",
    "\n",
    "http://zh.d2l.ai/chapter_deep-learning-basics/linear-regression-gluon.html\n",
    "    \n",
    "    \n",
    "3.3.8. 小结\n",
    "使用Gluon可以更简洁地实现模型。\n",
    "在Gluon中，data模块提供了有关数据处理的工具，nn模块定义了大量神经网络的层，loss模块定义了各种损失函数。\n",
    "MXNet的initializer模块提供了模型参数初始化的各种方法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
